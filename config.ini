[DEFAULT]
# Chat model configuration
chat_model_name = llama-3.1-8b-lexi-uncensored-v2
base_url = http://localhost:1234/v1/
openai_api_key = your-api-key-here

# Directory settings
sound_directory = sound-streams/
transcript_directory = transcript-streams/

# File management
keep_generated_file = false
generate_transcript = false

# Chat behavior
initial_content = "You are a personal asistant answering questions. Your name is {bot_name}. You will state users question first than answer."
read_after_generate = true
print_generated_text = true
memory_message_count = 5
bot_name = Lara
remove_deepseek_think_tags = false
bot_sound = tts_models/en/jenny/jenny

# System settings
speak_welcome = true
use_gpu = true
